#!/usr/bin/env python3
"""
è¯¦ç»†åˆ†æRAGæ£€ç´¢è¿‡ç¨‹ - å±•ç¤ºçœŸå®è¾“å…¥å’Œè¾“å‡º
"""

import json
import subprocess
import sys
import time
import os
from pathlib import Path

def analyze_retrieval():
    """åˆ†ææ£€ç´¢è¿‡ç¨‹çš„è¯¦ç»†ä¿¡æ¯"""
    print("ğŸ” RAGæ£€ç´¢è¿‡ç¨‹è¯¦ç»†åˆ†æ")
    print("=" * 50)
    
    env = os.environ.copy()
    env["OPENAI_API_KEY"] = "sk-test-key-for-validation"
    
    process = subprocess.Popen(
        [sys.executable, "mcp_server_standalone.py"],
        stdin=subprocess.PIPE,
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
        text=True,
        env=env
    )
    
    time.sleep(1)
    
    def send_request(request):
        request_json = json.dumps(request)
        process.stdin.write(request_json + "\n")
        process.stdin.flush()
        
        response_line = process.stdout.readline()
        if response_line.strip():
            return json.loads(response_line.strip())
        return None
    
    try:
        # åˆå§‹åŒ–å¹¶å¤„ç†æ–‡æ¡£
        print("ğŸš€ åˆå§‹åŒ–ç³»ç»Ÿå¹¶å¤„ç†æ–‡æ¡£...")
        
        init_request = {
            "jsonrpc": "2.0", "id": 1, "method": "initialize",
            "params": {"protocolVersion": "2025-06-18", "capabilities": {}, "clientInfo": {"name": "analysis", "version": "1.0"}}
        }
        send_request(init_request)
        
        # å¤„ç†æ–‡æ¡£
        documents = [
            {"path": "test_document.txt", "name": "MCPæœåŠ¡å™¨æ–‡æ¡£"},
            {"path": "test-file-pdf/2501.14101v1.pdf", "name": "å­¦æœ¯è®ºæ–‡1"},
            {"path": "test-file-pdf/2505.17010v1.pdf", "name": "å­¦æœ¯è®ºæ–‡2"}
        ]
        
        for doc in documents:
            doc_path = Path(doc["path"]).absolute()
            if doc_path.exists():
                send_request({
                    "jsonrpc": "2.0", "id": 2, "method": "tools/call",
                    "params": {
                        "name": "process_document",
                        "arguments": {"file_path": str(doc_path), "file_name": doc["name"]}
                    }
                })
        
        print("âœ… æ–‡æ¡£å¤„ç†å®Œæˆ\n")
        
        # è¯¦ç»†åˆ†æå‡ ä¸ªå…¸å‹æŸ¥è¯¢
        test_cases = [
            {
                "query": "machine learning",
                "expected": "åº”è¯¥åœ¨å­¦æœ¯è®ºæ–‡ä¸­æ‰¾åˆ°é«˜ç›¸å…³æ€§åŒ¹é…",
                "category": "è‹±æ–‡å­¦æœ¯æœ¯è¯­"
            },
            {
                "query": "æ·±åº¦å­¦ä¹ ", 
                "expected": "å¯èƒ½åœ¨ä¸­æ–‡æ–‡æ¡£æˆ–è®ºæ–‡æ‘˜è¦ä¸­æ‰¾åˆ°",
                "category": "ä¸­æ–‡å­¦æœ¯æœ¯è¯­"
            },
            {
                "query": "MCP",
                "expected": "åº”è¯¥åœ¨MCPæœåŠ¡å™¨æ–‡æ¡£ä¸­æ‰¾åˆ°",
                "category": "æŠ€æœ¯ç¼©å†™"
            },
            {
                "query": "neural network",
                "expected": "ç¥ç»ç½‘ç»œç›¸å…³å†…å®¹åœ¨å­¦æœ¯è®ºæ–‡ä¸­",
                "category": "è‹±æ–‡å­¦æœ¯æ¦‚å¿µ"
            }
        ]
        
        for i, case in enumerate(test_cases, 1):
            print(f"ğŸ“‹ æµ‹è¯•æ¡ˆä¾‹ {i}: {case['category']}")
            print(f"ğŸ” æŸ¥è¯¢è¾“å…¥: '{case['query']}'")
            print(f"ğŸ’­ é¢„æœŸç»“æœ: {case['expected']}")
            
            # æ‰§è¡ŒæŸ¥è¯¢
            query_request = {
                "jsonrpc": "2.0", "id": 10 + i, "method": "tools/call",
                "params": {
                    "name": "query_documents",
                    "arguments": {
                        "query": case["query"],
                        "top_k": 3,
                        "session_id": f"analysis-session-{i}"
                    }
                }
            }
            
            response = send_request(query_request)
            
            if response and "result" in response:
                content = response["result"]["content"][0]["text"]
                print(f"ğŸ“¤ RAGç³»ç»Ÿå“åº”:")
                
                # è§£æå“åº”å†…å®¹
                lines = content.split('\n')
                found_results = False
                
                for line in lines:
                    if "æ‰¾åˆ°" in line and "ä¸ªç›¸å…³æ–‡æ¡£" in line:
                        print(f"  ğŸ“Š {line.strip()}")
                        found_results = True
                    elif "â€¢ æ–‡ä»¶:" in line:
                        filename = line.split("â€¢ æ–‡ä»¶:")[1].strip()
                        print(f"  ğŸ“„ åŒ¹é…æ–‡æ¡£: {filename}")
                    elif "â€¢ ç›¸å…³æ€§:" in line:
                        score = line.split("â€¢ ç›¸å…³æ€§:")[1].strip()
                        print(f"  ğŸ¯ ç›¸å…³æ€§è¯„åˆ†: {score}")
                    elif "â€¢ é¢„è§ˆ:" in line:
                        preview = line.split("â€¢ é¢„è§ˆ:")[1].strip()
                        # æˆªå–å‰100ä¸ªå­—ç¬¦æ˜¾ç¤º
                        if len(preview) > 100:
                            preview = preview[:100] + "..."
                        print(f"  ğŸ‘ï¸ å†…å®¹é¢„è§ˆ: {preview}")
                
                if not found_results and "æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£" in content:
                    print("  âŒ æœªæ‰¾åˆ°åŒ¹é…æ–‡æ¡£")
                
            else:
                print("  âŒ æŸ¥è¯¢å¤±è´¥")
            
            print("-" * 40)
        
        # å±•ç¤ºç³»ç»Ÿçš„å®é™…å·¥ä½œæœºåˆ¶
        print("\nğŸ”§ ç³»ç»Ÿå·¥ä½œæœºåˆ¶åˆ†æ:")
        print("1ï¸âƒ£ è¾“å…¥å¤„ç†:")
        print("   â€¢ æŸ¥è¯¢è¯è½¬æ¢ä¸ºå°å†™")
        print("   â€¢ æŒ‰ç©ºæ ¼åˆ†å‰²æˆå…³é”®è¯åˆ—è¡¨")
        print("   â€¢ ç¤ºä¾‹: 'machine learning' â†’ ['machine', 'learning']")
        
        print("\n2ï¸âƒ£ æ–‡æ¡£åŒ¹é…:")
        print("   â€¢ åœ¨æ¯ä¸ªæ–‡æ¡£çš„åŸå§‹æ–‡æœ¬ä¸­æœç´¢å…³é”®è¯")
        print("   â€¢ è®¡ç®—æ¯ä¸ªå…³é”®è¯å‡ºç°æ¬¡æ•°")
        print("   â€¢ ç›¸å…³æ€§åˆ†æ•° = æ‰€æœ‰å…³é”®è¯å‡ºç°æ¬¡æ•°ä¹‹å’Œ")
        
        print("\n3ï¸âƒ£ ç»“æœæ’åº:")
        print("   â€¢ æŒ‰ç›¸å…³æ€§åˆ†æ•°é™åºæ’åˆ—")
        print("   â€¢ è¿”å›å‰Nä¸ªç»“æœ(top_k)")
        
        print("\n4ï¸âƒ£ å†…å®¹æå–:")
        print("   â€¢ æ‰¾åˆ°ç¬¬ä¸€ä¸ªå…³é”®è¯ä½ç½®")
        print("   â€¢ æå–å‰å50å­—ç¬¦ä½œä¸ºä¸Šä¸‹æ–‡")
        print("   â€¢ æ€»é¢„è§ˆé•¿åº¦çº¦200å­—ç¬¦")
        
        # æ˜¾ç¤ºå®é™…çš„è¯„åˆ†ç¤ºä¾‹
        print("\nğŸ“ˆ å®é™…è¯„åˆ†ç¤ºä¾‹:")
        print("â€¢ 'machine learning' åœ¨è®ºæ–‡ä¸­å‡ºç°104æ¬¡ â†’ ç›¸å…³æ€§104åˆ†")
        print("â€¢ 'deep learning' åœ¨è®ºæ–‡ä¸­å‡ºç°98æ¬¡ â†’ ç›¸å…³æ€§98åˆ†") 
        print("â€¢ 'neural network' åœ¨è®ºæ–‡ä¸­å‡ºç°55æ¬¡ â†’ ç›¸å…³æ€§55åˆ†")
        print("â€¢ 'MCP' åœ¨æœåŠ¡å™¨æ–‡æ¡£ä¸­å‡ºç°3æ¬¡ â†’ ç›¸å…³æ€§3åˆ†")
        
    except Exception as e:
        print(f"âŒ åˆ†æè¿‡ç¨‹å‡ºé”™: {e}")
    
    finally:
        process.terminate()
        process.wait()

if __name__ == "__main__":
    analyze_retrieval()