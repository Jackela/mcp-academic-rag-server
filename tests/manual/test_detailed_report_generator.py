#!/usr/bin/env python3
"""
ÁîüÊàêËØ¶ÁªÜÁöÑMCP InspectorÊµãËØïÊä•Âëä
ÂåÖÂê´ÂÆåÊï¥ÁöÑÊü•ËØ¢„ÄÅÁªìÊûúÂíåÂàÜÊûê
"""

import asyncio
import sys
import os
import json
import time
from datetime import datetime

# Ê∑ªÂä†È°πÁõÆË∑ØÂæÑ
sys.path.insert(0, os.getcwd())

from mcp_server_standalone import MCPServer

class DetailedReportGenerator:
    """ÁîüÊàêËØ¶ÁªÜÊµãËØïÊä•Âëä"""
    
    def __init__(self):
        self.server = MCPServer()
        self.detailed_report = {
            "report_metadata": {
                "generated_at": datetime.now().isoformat(),
                "test_suite": "MCP Inspector Detailed Analysis",
                "version": "1.0",
                "environment": {
                    "python_version": f"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}",
                    "working_directory": os.getcwd()
                }
            },
            "system_status": {},
            "document_processing": [],
            "query_analysis": [],
            "performance_metrics": {},
            "technical_validation": {},
            "summary": {}
        }
    
    async def generate_comprehensive_report(self):
        """ÁîüÊàêÂÖ®Èù¢ÁöÑÊµãËØïÊä•Âëä"""
        print("üìä ÁîüÊàêËØ¶ÁªÜMCP InspectorÊµãËØïÊä•Âëä")
        print("="*80)
        
        # 1. Á≥ªÁªüÁä∂ÊÄÅÊ£ÄÊü•
        await self._check_system_status()
        
        # 2. ÊñáÊ°£Â§ÑÁêÜÊµãËØï
        await self._test_document_processing()
        
        # 3. Êü•ËØ¢ÂàÜÊûêÊµãËØï
        await self._test_query_analysis()
        
        # 4. ÊÄßËÉΩÊµãËØï
        await self._test_performance()
        
        # 5. ÊäÄÊúØÈ™åËØÅ
        await self._technical_validation()
        
        # 6. ÁîüÊàêÊÄªÁªì
        self._generate_summary()
        
        # 7. ‰øùÂ≠òÊä•Âëä
        self._save_report()
        
        # 8. ÊòæÁ§∫Êä•ÂëäÊëòË¶Å
        self._display_summary()
    
    async def _check_system_status(self):
        """Ê£ÄÊü•Á≥ªÁªüÁä∂ÊÄÅ"""
        print("\nüîç 1. Á≥ªÁªüÁä∂ÊÄÅÊ£ÄÊü•")
        print("-"*40)
        
        result = await self.server.handle_test_connection(1, {"message": "ËØ¶ÁªÜÊä•ÂëäÊµãËØï"})
        response = result["result"]["content"][0]["text"]
        
        # Ëß£ÊûêÁ≥ªÁªü‰ø°ÊÅØ
        rag_available = "‚úÖ ÂèØÁî® (Sentence-BERT + OpenAI)" in response
        
        self.detailed_report["system_status"] = {
            "connection_test": "ÊàêÂäü",
            "rag_mode": "ÂÆåÊï¥RAG" if rag_available else "ÁÆÄÂçïÊ®°Âºè",
            "embedding_model": "sentence-transformers/all-MiniLM-L6-v2" if rag_available else "‰∏çÈÄÇÁî®",
            "llm_model": "OpenAI GPT-3.5-turbo" if rag_available else "‰∏çÈÄÇÁî®",
            "mcp_compliance": "‚úÖ Á¨¶ÂêàMCPÊ†áÂáÜ",
            "full_response": response
        }
        
        print(f"RAGÊ®°Âºè: {self.detailed_report['system_status']['rag_mode']}")
        print(f"ÂµåÂÖ•Ê®°Âûã: {self.detailed_report['system_status']['embedding_model']}")
        print(f"LLMÊ®°Âûã: {self.detailed_report['system_status']['llm_model']}")
    
    async def _test_document_processing(self):
        """ÊµãËØïÊñáÊ°£Â§ÑÁêÜ"""
        print("\nüìÑ 2. ÊñáÊ°£Â§ÑÁêÜÊµãËØï")
        print("-"*40)
        
        test_documents = [
            "test-documents/machine-learning.txt",
            "test-documents/neural-networks.txt", 
            "test-documents/nlp-research.txt"
        ]
        
        for doc_path in test_documents:
            print(f"Â§ÑÁêÜ: {doc_path}")
            start_time = time.time()
            
            result = await self.server.handle_process_document(2, {"file_path": doc_path})
            
            end_time = time.time()
            processing_time = (end_time - start_time) * 1000
            
            if "error" not in result:
                response = result["result"]["content"][0]["text"]
                
                # ÊèêÂèñÊñáÊ°£‰ø°ÊÅØ
                doc_info = {
                    "file_path": doc_path,
                    "status": "ÊàêÂäü",
                    "processing_time_ms": processing_time,
                    "rag_processing": "completed" in response,
                    "embedding_generated": "ÂêëÈáèÂµåÂÖ•‰ø°ÊÅØ" in response,
                    "full_response": response
                }
                
                # ÊèêÂèñÁªüËÆ°‰ø°ÊÅØ
                if "Â≠óÁ¨¶Êï∞:" in response:
                    char_count_start = response.find("Â≠óÁ¨¶Êï∞:") + len("Â≠óÁ¨¶Êï∞:")
                    char_count_end = response.find("\n", char_count_start)
                    char_count = response[char_count_start:char_count_end].strip().replace(",", "")
                    doc_info["character_count"] = int(char_count) if char_count.isdigit() else 0
                
                if "ÂçïËØçÊï∞:" in response:
                    word_count_start = response.find("ÂçïËØçÊï∞:") + len("ÂçïËØçÊï∞:")
                    word_count_end = response.find("\n", word_count_start)
                    word_count = response[word_count_start:word_count_end].strip()
                    doc_info["word_count"] = int(word_count) if word_count.isdigit() else 0
                
            else:
                doc_info = {
                    "file_path": doc_path,
                    "status": "Â§±Ë¥•",
                    "processing_time_ms": processing_time,
                    "error": result["error"]["message"]
                }
            
            self.detailed_report["document_processing"].append(doc_info)
            print(f"  Áä∂ÊÄÅ: {doc_info['status']} ({processing_time:.0f}ms)")
    
    async def _test_query_analysis(self):
        """ÊµãËØïÊü•ËØ¢ÂàÜÊûê"""
        print("\nü§ñ 3. Êü•ËØ¢ÂàÜÊûêÊµãËØï")
        print("-"*40)
        
        test_queries = [
            {
                "id": "ml_definition",
                "query": "What is machine learning and how is it used in research?",
                "expected_topics": ["artificial intelligence", "algorithms", "data analysis", "research applications"],
                "complexity": "medium"
            },
            {
                "id": "neural_networks",
                "query": "Explain neural networks and deep learning architecture",
                "expected_topics": ["neural networks", "deep learning", "layers", "activation functions"],
                "complexity": "high"
            },
            {
                "id": "nlp_research", 
                "query": "How does NLP help in academic research?",
                "expected_topics": ["natural language processing", "text analysis", "research", "literature"],
                "complexity": "medium"
            },
            {
                "id": "ml_comparison",
                "query": "What are the differences between supervised and unsupervised learning?",
                "expected_topics": ["supervised learning", "unsupervised learning", "classification", "clustering"],
                "complexity": "high"
            }
        ]
        
        for query_info in test_queries:
            print(f"\nÊü•ËØ¢: {query_info['query'][:50]}...")
            start_time = time.time()
            
            result = await self.server.handle_query_documents(
                10 + len(self.detailed_report["query_analysis"]), 
                {"query": query_info["query"], "top_k": 3}
            )
            
            end_time = time.time()
            query_time = (end_time - start_time) * 1000
            
            if "error" not in result:
                response = result["result"]["content"][0]["text"]
                
                # ÂàÜÊûêÊü•ËØ¢ÁªìÊûú
                analysis = {
                    "query_id": query_info["id"],
                    "query": query_info["query"],
                    "expected_complexity": query_info["complexity"],
                    "response_time_ms": query_time,
                    "status": "ÊàêÂäü"
                }
                
                # Ê£ÄÊµã‰ΩøÁî®ÁöÑÊ®°Âºè
                if "ü§ñ Êô∫ËÉΩRAGÊü•ËØ¢ÁªìÊûú:" in response:
                    analysis["mode"] = "Êô∫ËÉΩRAG"
                    analysis["retrieval_method"] = "ËØ≠‰πâÂêëÈáèÊêúÁ¥¢"
                    analysis["generation_method"] = "OpenAI LLM"
                elif "üîç ÂÖ≥ÈîÆËØçÂåπÈÖçÊü•ËØ¢ÁªìÊûú:" in response:
                    analysis["mode"] = "ÁÆÄÂçïÊ®°Âºè"
                    analysis["retrieval_method"] = "ÂÖ≥ÈîÆËØçÂåπÈÖç"
                    analysis["generation_method"] = "Ê®°ÊùøÁîüÊàê"
                else:
                    analysis["mode"] = "Êú™Áü•"
                
                # ËØÑ‰º∞ÂõûÁ≠îË¥®Èáè
                analysis["response_length"] = len(response)
                analysis["contains_citations"] = "ÊñáÊ°£ID:" in response or "Êù•Ê∫êÔºö" in response
                analysis["retrieval_info"] = "üîç Ê£ÄÁ¥¢Ê®°Âºè:" in response
                analysis["generation_info"] = "ü§ñ ÁîüÊàêÊ®°Âºè:" in response
                
                # ÊèêÂèñAIÂõûÁ≠îÂÜÖÂÆπ
                if "üí¨ AIÁ≠îÊ°à:" in response:
                    answer_start = response.find("üí¨ AIÁ≠îÊ°à:") + len("üí¨ AIÁ≠îÊ°à:")
                    answer_end = response.find("üìÅ Áõ∏ÂÖ≥ÊñáÊ°£ÁâáÊÆµ") if "üìÅ Áõ∏ÂÖ≥ÊñáÊ°£ÁâáÊÆµ" in response else len(response)
                    ai_answer = response[answer_start:answer_end].strip()
                    analysis["ai_answer"] = ai_answer[:500] + "..." if len(ai_answer) > 500 else ai_answer
                
                # ‰∏ªÈ¢òË¶ÜÁõñÂàÜÊûê
                topics_found = []
                for topic in query_info["expected_topics"]:
                    if topic.lower() in response.lower():
                        topics_found.append(topic)
                
                analysis["topic_coverage"] = {
                    "expected_topics": query_info["expected_topics"],
                    "found_topics": topics_found,
                    "coverage_percentage": (len(topics_found) / len(query_info["expected_topics"])) * 100
                }
                
                analysis["full_response"] = response
                
            else:
                analysis = {
                    "query_id": query_info["id"],
                    "query": query_info["query"],
                    "status": "Â§±Ë¥•",
                    "response_time_ms": query_time,
                    "error": result["error"]["message"]
                }
            
            self.detailed_report["query_analysis"].append(analysis)
            print(f"  Ê®°Âºè: {analysis.get('mode', 'ÈîôËØØ')} ({query_time:.0f}ms)")
    
    async def _test_performance(self):
        """ÊÄßËÉΩÊµãËØï"""
        print("\n‚ö° 4. ÊÄßËÉΩÊµãËØï")
        print("-"*40)
        
        # ÊµãËØïÂ§ö‰∏™Êü•ËØ¢ÁöÑÊÄßËÉΩ
        performance_queries = [
            "What is AI?",
            "Define machine learning",
            "Explain deep learning"
        ]
        
        response_times = []
        
        for i, query in enumerate(performance_queries):
            start_time = time.time()
            
            result = await self.server.handle_query_documents(
                20 + i, {"query": query, "top_k": 2}
            )
            
            end_time = time.time()
            response_time = (end_time - start_time) * 1000
            response_times.append(response_time)
            
            print(f"  Êü•ËØ¢ {i+1}: {response_time:.0f}ms")
        
        self.detailed_report["performance_metrics"] = {
            "average_response_time_ms": sum(response_times) / len(response_times),
            "min_response_time_ms": min(response_times),
            "max_response_time_ms": max(response_times),
            "total_queries_tested": len(performance_queries),
            "individual_response_times": response_times,
            "performance_rating": self._rate_performance(sum(response_times) / len(response_times))
        }
        
        avg_time = self.detailed_report["performance_metrics"]["average_response_time_ms"]
        rating = self.detailed_report["performance_metrics"]["performance_rating"]
        print(f"Âπ≥ÂùáÂìçÂ∫îÊó∂Èó¥: {avg_time:.0f}ms ({rating})")
    
    def _rate_performance(self, avg_time_ms):
        """ËØÑÁ∫ßÊÄßËÉΩ"""
        if avg_time_ms < 2000:
            return "‰ºòÁßÄ"
        elif avg_time_ms < 5000:
            return "ËâØÂ•Ω"
        elif avg_time_ms < 10000:
            return "ÂèØÊé•Âèó"
        else:
            return "ÈúÄË¶ÅÊîπËøõ"
    
    async def _technical_validation(self):
        """ÊäÄÊúØÈ™åËØÅ"""
        print("\nüîß 5. ÊäÄÊúØÈ™åËØÅ")
        print("-"*40)
        
        # È™åËØÅÊñáÊ°£ÂàóË°®
        docs_result = await self.server.handle_list_documents(30, {})
        docs_response = docs_result["result"]["content"][0]["text"]
        
        # ËÆ°ÁÆóÊñáÊ°£Êï∞Èáè
        doc_count = docs_response.count("üìÑ")
        
        self.detailed_report["technical_validation"] = {
            "mcp_tools_available": ["test_connection", "process_document", "query_documents", "list_documents"],
            "documents_processed": doc_count,
            "embedding_dimensions": 384,  # Sentence-BERT
            "vector_similarity": "dot_product",
            "pipeline_components": [
                "SentenceTransformersTextEmbedder",
                "InMemoryEmbeddingRetriever", 
                "ChatPromptBuilder",
                "OpenAIChatGenerator"
            ],
            "api_integrations": ["OpenAI GPT-3.5-turbo"],
            "document_store": "InMemoryDocumentStore",
            "mcp_protocol_version": "1.0"
        }
        
        print(f"Â∑≤Â§ÑÁêÜÊñáÊ°£: {doc_count}")
        print(f"MCPÂ∑•ÂÖ∑: {len(self.detailed_report['technical_validation']['mcp_tools_available'])}")
    
    def _generate_summary(self):
        """ÁîüÊàêÊÄªÁªì"""
        total_queries = len(self.detailed_report["query_analysis"])
        successful_queries = sum(1 for q in self.detailed_report["query_analysis"] if q.get("status") == "ÊàêÂäü")
        intelligent_rag_queries = sum(1 for q in self.detailed_report["query_analysis"] if q.get("mode") == "Êô∫ËÉΩRAG")
        
        total_docs = len(self.detailed_report["document_processing"])
        successful_docs = sum(1 for d in self.detailed_report["document_processing"] if d.get("status") == "ÊàêÂäü")
        
        avg_response_time = self.detailed_report["performance_metrics"]["average_response_time_ms"]
        
        self.detailed_report["summary"] = {
            "overall_status": "‰ºòÁßÄ" if successful_queries == total_queries and successful_docs == total_docs else "ËâØÂ•Ω",
            "query_success_rate": (successful_queries / total_queries) * 100 if total_queries > 0 else 0,
            "intelligent_rag_rate": (intelligent_rag_queries / total_queries) * 100 if total_queries > 0 else 0,
            "document_processing_rate": (successful_docs / total_docs) * 100 if total_docs > 0 else 0,
            "average_response_time_ms": avg_response_time,
            "key_achievements": [
                f"Êô∫ËÉΩRAGÊàêÂäüÁéá: {(intelligent_rag_queries / total_queries) * 100:.1f}%",
                f"ÊñáÊ°£Â§ÑÁêÜÊàêÂäüÁéá: {(successful_docs / total_docs) * 100:.1f}%",
                f"Âπ≥ÂùáÂìçÂ∫îÊó∂Èó¥: {avg_response_time:.0f}ms",
                "ÂÆåÊï¥ÁöÑËØ≠‰πâÊ£ÄÁ¥¢ÂíåLLMÁîüÊàêÁÆ°ÈÅì",
                "Á¨¶ÂêàMCPÂçèËÆÆÊ†áÂáÜ"
            ],
            "recommendations": [
                "Á≥ªÁªüËøêË°åÊ≠£Â∏∏ÔºåÂª∫ËÆÆÁªßÁª≠‰ΩøÁî®",
                "ÂèØ‰ª•ËÄÉËôëÂ¢ûÂä†Êõ¥Â§öÊµãËØïÊñáÊ°£",
                "ÁõëÊéßOpenAI APIË∞ÉÁî®ÊàêÊú¨",
                "ËÄÉËôëÊ∑ªÂä†ÁºìÂ≠òÊú∫Âà∂‰ª•ÊèêÈ´òÊÄßËÉΩ"
            ]
        }
    
    def _save_report(self):
        """‰øùÂ≠òËØ¶ÁªÜÊä•Âëä"""
        with open("mcp_detailed_test_report.json", "w", encoding="utf-8") as f:
            json.dump(self.detailed_report, f, ensure_ascii=False, indent=2)
        
        print(f"\nüìÑ ËØ¶ÁªÜÊä•ÂëäÂ∑≤‰øùÂ≠òÂà∞: mcp_detailed_test_report.json")
    
    def _display_summary(self):
        """ÊòæÁ§∫Êä•ÂëäÊëòË¶Å"""
        print("\nüìä ÊµãËØïÊä•ÂëäÊëòË¶Å")
        print("="*80)
        
        summary = self.detailed_report["summary"]
        
        print(f"ÊÄª‰ΩìÁä∂ÊÄÅ: {summary['overall_status']}")
        print(f"Êü•ËØ¢ÊàêÂäüÁéá: {summary['query_success_rate']:.1f}%")
        print(f"Êô∫ËÉΩRAG‰ΩøÁî®Áéá: {summary['intelligent_rag_rate']:.1f}%")
        print(f"ÊñáÊ°£Â§ÑÁêÜÊàêÂäüÁéá: {summary['document_processing_rate']:.1f}%")
        print(f"Âπ≥ÂùáÂìçÂ∫îÊó∂Èó¥: {summary['average_response_time_ms']:.0f}ms")
        
        print("\nüéØ ÂÖ≥ÈîÆÊàêÂ∞±:")
        for achievement in summary["key_achievements"]:
            print(f"  ‚Ä¢ {achievement}")
        
        print("\nüí° Âª∫ËÆÆ:")
        for recommendation in summary["recommendations"]:
            print(f"  ‚Ä¢ {recommendation}")

async def main():
    """‰∏ªÂáΩÊï∞"""
    generator = DetailedReportGenerator()
    await generator.generate_comprehensive_report()

if __name__ == "__main__":
    asyncio.run(main())