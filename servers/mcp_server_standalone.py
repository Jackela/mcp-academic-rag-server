#!/usr/bin/env python3
"""
Standalone MCP Academic RAG Server - æ¸è¿›å¼å¢å¼ºç‰ˆæœ¬
é‡ç”¨ç°æœ‰æ¶æ„ä½†æä¾›ç‹¬ç«‹çš„ä¾èµ–ç®¡ç†
"""

import asyncio
import json
import sys
import os
import logging
from pathlib import Path
from typing import Dict, Any, List, Optional
import uuid
import time

# é…ç½®æ—¥å¿—åˆ°stderr (MCPè¦æ±‚) - å¿…é¡»åœ¨å…¶ä»–æ¨¡å—å¼•ç”¨loggerä¹‹å‰
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    stream=sys.stderr
)
logger = logging.getLogger("mcp-academic-rag-standalone")

# é‡ç”¨ç°æœ‰æ¨¡å‹å’Œæ ¸å¿ƒç»„ä»¶
try:
    from models.document import Document
    from core.server_context import ServerContext
    from rag.haystack_pipeline import RAGPipeline
    from connectors.haystack_llm_connector import HaystackLLMConnector
    from document_stores.haystack_store import HaystackDocumentStore
    from processors.haystack_embedding_processor import HaystackEmbeddingProcessor
    HAS_FULL_DEPS = True
    logger.info("âœ… å®Œæ•´RAGä¾èµ–å·²åŠ è½½")
except ImportError as e:
    # å¦‚æœä¾èµ–ä¸å¯ç”¨ï¼Œä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬
    HAS_FULL_DEPS = False
    logger.warning(f"âš ï¸ å®Œæ•´RAGä¾èµ–ä¸å¯ç”¨: {e}")
    
    class Document:
        """ç®€åŒ–çš„æ–‡æ¡£ç±»"""
        def __init__(self, file_path: str):
            self.document_id = str(uuid.uuid4())
            self.file_path = file_path
            self.file_name = os.path.basename(file_path)
            self.file_type = os.path.splitext(file_path)[1].lower()
            self.creation_time = time.strftime("%Y-%m-%d %H:%M:%S")
            self.status = "new"
            self.metadata = {}
            self.content = {}
        
        def store_content(self, stage: str, content: str):
            """å­˜å‚¨å†…å®¹åˆ°æŒ‡å®šé˜¶æ®µ"""
            self.content[stage] = content
        
        def get_content(self, stage: str):
            """è·å–æŒ‡å®šé˜¶æ®µçš„å†…å®¹"""
            return self.content.get(stage)
    
    class ServerContext:
        """ç®€åŒ–çš„æœåŠ¡å™¨ä¸Šä¸‹æ–‡"""
        def __init__(self):
            self._initialized = False
        
        def initialize(self):
            self._initialized = True
        
        @property
        def is_initialized(self):
            return self._initialized
        
        def get_status(self):
            return {
                "initialized": self._initialized,
                "config_loaded": False,
                "pipeline_ready": False,
                "rag_enabled": False,
                "processors_count": 0
            }

class SimpleDocumentProcessor:
    """å¢å¼ºçš„æ–‡æ¡£å¤„ç†å™¨ - æ”¯æŒPDFå¹¶é‡ç”¨Documentæ¨¡å‹"""
    
    def __init__(self, mcp_server=None):
        self.documents: Dict[str, Document] = {}
        self.mcp_server = mcp_server  # å¼•ç”¨çˆ¶æœåŠ¡å™¨ä»¥è®¿é—®RAGç»„ä»¶
    
    def process_pdf(self, file_path: str) -> str:
        """å¤„ç†PDFæ–‡ä»¶ - å°è¯•å¤šç§æ–¹æ³•"""
        try:
            # æ–¹æ³•1: å°è¯•ä½¿ç”¨PyPDF2 (å¦‚æœå¯ç”¨)
            try:
                import PyPDF2
                with open(file_path, 'rb') as f:
                    reader = PyPDF2.PdfReader(f)
                    text = ""
                    for page in reader.pages:
                        text += page.extract_text() + "\n"
                    if text.strip():
                        return text
            except ImportError:
                pass
            except Exception:
                pass
            
            # æ–¹æ³•2: å°è¯•ä½¿ç”¨pdfplumber (å¦‚æœå¯ç”¨)
            try:
                import pdfplumber
                with pdfplumber.open(file_path) as pdf:
                    text = ""
                    for page in pdf.pages:
                        page_text = page.extract_text()
                        if page_text:
                            text += page_text + "\n"
                    if text.strip():
                        return text
            except ImportError:
                pass
            except Exception:
                pass
            
            # æ–¹æ³•3: å°è¯•ä½¿ç”¨pdfminer (å¦‚æœå¯ç”¨)
            try:
                from pdfminer.high_level import extract_text
                text = extract_text(file_path)
                if text.strip():
                    return text
            except ImportError:
                pass
            except Exception:
                pass
            
            # æ–¹æ³•4: ä½¿ç”¨ç°æœ‰çš„OCRå¤„ç†å™¨ (å¦‚æœå¯ç”¨)
            if HAS_FULL_DEPS:
                try:
                    from processors.ocr_processor import OCRProcessor
                    processor = OCRProcessor()
                    # è¿™é‡Œéœ€è¦å…ˆå°†PDFè½¬æ¢ä¸ºå›¾åƒï¼Œç„¶åOCR
                    # ä¸ºç®€åŒ–ï¼Œæˆ‘ä»¬æš‚æ—¶è·³è¿‡è¿™ä¸ªæ–¹æ³•
                    pass
                except ImportError:
                    pass
            
            # å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥ï¼Œè¿”å›é”™è¯¯ä¿¡æ¯
            raise Exception("PDFå¤„ç†å¤±è´¥ï¼šéœ€è¦å®‰è£… PyPDF2, pdfplumber æˆ– pdfminer3 ä¹‹ä¸€")
            
        except Exception as e:
            raise Exception(f"PDFå¤„ç†é”™è¯¯: {str(e)}")
    
    def process_document(self, file_path: str) -> Dict[str, Any]:
        """å¤„ç†æ–‡æ¡£å¹¶å­˜å‚¨ - æ”¯æŒPDFå’Œå®Œæ•´RAGç®¡é“"""
        try:
            document = Document(file_path)
            file_ext = document.file_type.lower()
            
            # è¯»å–æ–‡ä»¶å†…å®¹
            if file_ext == '.pdf':
                content = self.process_pdf(file_path)
                document.metadata['processing_method'] = 'pdf_extraction'
            else:
                # å¤„ç†æ–‡æœ¬æ–‡ä»¶
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                document.metadata['processing_method'] = 'text_file'
            
            # å­˜å‚¨åŸå§‹å†…å®¹
            document.content['raw_text'] = content
            document.metadata.update({
                'word_count': len(content.split()),
                'char_count': len(content),
                'line_count': len(content.splitlines())
            })
            
            # å¦‚æœå®Œæ•´RAGå¯ç”¨ï¼Œä½¿ç”¨åµŒå…¥å¤„ç†å™¨
            embedding_result = None
            if (self.mcp_server and 
                hasattr(self.mcp_server, 'full_rag_available') and 
                self.mcp_server.full_rag_available and 
                hasattr(self.mcp_server, 'embedding_processor')):
                try:
                    logger.info(f"ğŸš€ ä½¿ç”¨å®Œæ•´RAGç®¡é“å¤„ç†æ–‡æ¡£: {document.file_name}")
                    
                    # ä½¿ç”¨åµŒå…¥å¤„ç†å™¨å¤„ç†æ–‡æ¡£
                    # é¦–å…ˆä¸ºæ–‡æ¡£æ·»åŠ OCRå¤„ç†çš„å†…å®¹ï¼ˆæ¨¡æ‹Ÿå·²å¤„ç†ï¼‰
                    document.store_content("OCRProcessor", content)
                    
                    # ä½¿ç”¨åµŒå…¥å¤„ç†å™¨ç”Ÿæˆå‘é‡åµŒå…¥
                    embedding_result = self.mcp_server.embedding_processor.process(document)
                    
                    if embedding_result.is_successful():
                        result_data = embedding_result.get_data()
                        document.metadata.update({
                            'chunks_count': result_data.get('chunks', 0),
                            'embedding_model': 'sentence-transformers/all-MiniLM-L6-v2',
                            'rag_processing': 'completed'
                        })
                        logger.info(f"âœ… æ–‡æ¡£åµŒå…¥å¤„ç†å®Œæˆ: {result_data.get('chunks', 0)} ä¸ªå—")
                    else:
                        logger.warning(f"âš ï¸ åµŒå…¥å¤„ç†å¤±è´¥: {embedding_result.get_message()}")
                        document.metadata['rag_processing'] = 'failed'
                        
                except Exception as e:
                    logger.error(f"âŒ åµŒå…¥å¤„ç†å¼‚å¸¸: {e}", exc_info=True)
                    document.metadata['rag_processing'] = 'error'
            else:
                logger.info(f"ğŸ” ä½¿ç”¨ç®€å•å…³é”®è¯åŒ¹é…æ¨¡å¼å¤„ç†æ–‡æ¡£: {document.file_name}")
                document.metadata['rag_processing'] = 'simple_mode'
            
            document.status = "completed"
            
            # å­˜å‚¨æ–‡æ¡£
            self.documents[document.document_id] = document
            
            return {
                "success": True,
                "document_id": document.document_id,
                "document": document,
                "embedding_result": embedding_result.get_data() if embedding_result and embedding_result.is_successful() else None
            }
            
        except Exception as e:
            logger.error(f"âŒ æ–‡æ¡£å¤„ç†å¼‚å¸¸: {e}", exc_info=True)
            return {
                "success": False,
                "error": str(e)
            }
    
    def search_documents(self, query: str, top_k: int = 3) -> List[Dict[str, Any]]:
        """æœç´¢æ–‡æ¡£ - ç®€å•å…³é”®è¯åŒ¹é…"""
        results = []
        query_lower = query.lower()
        
        for doc_id, doc in self.documents.items():
            content = doc.content.get('raw_text', '')
            content_lower = content.lower()
            
            # è®¡ç®—åŒ¹é…åˆ†æ•°
            score = 0
            for word in query_lower.split():
                score += content_lower.count(word)
            
            if score > 0:
                # æå–ç›¸å…³ç‰‡æ®µ
                snippet_start = max(0, content_lower.find(query_lower.split()[0]) - 50)
                snippet_end = min(len(content), snippet_start + 200)
                snippet = content[snippet_start:snippet_end]
                
                results.append({
                    "document": doc,
                    "score": score,
                    "snippet": snippet.strip()
                })
        
        # æŒ‰åˆ†æ•°æ’åº
        results.sort(key=lambda x: x["score"], reverse=True)
        return results[:top_k]

class MCPServer:
    """å¢å¼ºçš„MCPæœåŠ¡å™¨å®ç° - é‡ç”¨ç°æœ‰æ¶æ„"""
    
    def __init__(self):
        # ä½¿ç”¨ä¾èµ–æ³¨å…¥æ¨¡å¼
        self.server_context = ServerContext()
        self.document_processor = SimpleDocumentProcessor(mcp_server=self)
        
        # å°è¯•åˆå§‹åŒ–çœŸæ­£çš„RAGç®¡é“
        self._try_initialize_full_rag()
        
        # æ‰©å±•å·¥å…·åˆ—è¡¨ - é‡ç”¨SDKæ¶æ„
        self.tools = [
            {
                "name": "test_connection",
                "description": "æµ‹è¯•MCPæœåŠ¡å™¨è¿æ¥çŠ¶æ€",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "message": {
                            "type": "string",
                            "description": "æµ‹è¯•æ¶ˆæ¯",
                            "default": "Hello MCP!"
                        }
                    },
                    "required": []
                }
            },
            {
                "name": "validate_system", 
                "description": "éªŒè¯æœåŠ¡å™¨ç³»ç»Ÿé…ç½®å’Œä¾èµ–",
                "inputSchema": {
                    "type": "object",
                    "properties": {},
                    "required": []
                }
            },
            {
                "name": "process_document",
                "description": "å¤„ç†å­¦æœ¯æ–‡æ¡£å¹¶å»ºç«‹ç´¢å¼•ï¼ˆæ”¯æŒæ–‡æœ¬æ–‡ä»¶ï¼‰",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "file_path": {
                            "type": "string",
                            "description": "è¦å¤„ç†çš„æ–‡æ¡£æ–‡ä»¶è·¯å¾„"
                        },
                        "file_name": {
                            "type": "string",
                            "description": "å¯é€‰çš„æ–‡æ¡£åç§°"
                        }
                    },
                    "required": ["file_path"]
                }
            },
            {
                "name": "query_documents",
                "description": "ä½¿ç”¨RAGæŸ¥è¯¢å·²å¤„ç†çš„æ–‡æ¡£",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "query": {
                            "type": "string",
                            "description": "è¦æŸ¥è¯¢çš„é—®é¢˜"
                        },
                        "session_id": {
                            "type": "string",
                            "description": "å¯é€‰çš„ä¼šè¯IDç”¨äºä¸Šä¸‹æ–‡"
                        },
                        "top_k": {
                            "type": "integer",
                            "description": "è¿”å›çš„ç›¸å…³æ–‡æ¡£æ•°é‡",
                            "default": 5
                        }
                    },
                    "required": ["query"]
                }
            },
            {
                "name": "list_documents",
                "description": "åˆ—å‡ºæ‰€æœ‰å·²å¤„ç†çš„æ–‡æ¡£",
                "inputSchema": {
                    "type": "object",
                    "properties": {},
                    "required": []
                }
            }
        ]
    
    def validate_api_key(self, api_key: str) -> bool:
        """éªŒè¯OpenAI APIå¯†é’¥æ ¼å¼"""
        if not api_key or not isinstance(api_key, str):
            return False
        if api_key != api_key.strip() or ' ' in api_key:
            return False
        if not api_key.startswith('sk-'):
            return False
        if len(api_key) < 21:
            return False
        return True
    
    def validate_environment(self) -> Dict[str, Any]:
        """éªŒè¯ç¯å¢ƒé…ç½®"""
        result = {
            "api_key_valid": False,
            "data_path_exists": False,
            "python_version": f"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}",
            "working_directory": os.getcwd(),
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
        }
        
        # æ£€æŸ¥APIå¯†é’¥
        api_key = os.environ.get('OPENAI_API_KEY')
        result["api_key_valid"] = self.validate_api_key(api_key)
        result["api_key_length"] = len(api_key) if api_key else 0
        
        # æ£€æŸ¥æ•°æ®ç›®å½•
        data_path = os.environ.get('DATA_PATH', './data')
        try:
            Path(data_path).mkdir(parents=True, exist_ok=True)
            result["data_path_exists"] = True
            result["data_path"] = str(Path(data_path).absolute())
        except Exception as e:
            result["data_path_error"] = str(e)
        
        return result
    
    async def handle_list_tools(self, request_id: Any) -> Dict[str, Any]:
        """å¤„ç†å·¥å…·åˆ—è¡¨è¯·æ±‚"""
        logger.info("Handling tools/list request")
        return {
            "jsonrpc": "2.0",
            "result": {
                "tools": self.tools
            },
            "id": request_id
        }
    
    async def handle_call_tool(self, request_id: Any, params: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†å·¥å…·è°ƒç”¨è¯·æ±‚"""
        tool_name = params.get("name")
        arguments = params.get("arguments", {})
        
        logger.info(f"Handling tool call: {tool_name} with args: {arguments}")
        
        try:
            if tool_name == "test_connection":
                return await self.handle_test_connection(request_id, arguments)
                
                
            elif tool_name == "validate_system":
                return await self.handle_validate_system(request_id, arguments)
                
            elif tool_name == "process_document":
                return await self.handle_process_document(request_id, arguments)
                
            elif tool_name == "query_documents":
                return await self.handle_query_documents(request_id, arguments)
                
            elif tool_name == "list_documents":
                return await self.handle_list_documents(request_id, arguments)
                
            else:
                result_text = f"âŒ æœªçŸ¥å·¥å…·: {tool_name}\nå¯ç”¨å·¥å…·: {', '.join([t['name'] for t in self.tools])}"
                return {
                    "jsonrpc": "2.0",
                    "result": {
                        "content": [
                            {
                                "type": "text",
                                "text": result_text
                            }
                        ]
                    },
                    "id": request_id
                }
            
        except Exception as e:
            logger.error(f"Tool call error: {str(e)}", exc_info=True)
            return {
                "jsonrpc": "2.0",
                "error": {
                    "code": -32603,
                    "message": f"å·¥å…·æ‰§è¡Œé”™è¯¯: {str(e)}"
                },
                "id": request_id
            }
    
    async def handle_initialize(self, request_id: Any, params: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†åˆå§‹åŒ–è¯·æ±‚"""
        logger.info("Handling initialize request")
        return {
            "jsonrpc": "2.0",
            "result": {
                "protocolVersion": "2025-06-18",
                "capabilities": {
                    "tools": {
                        "listChanged": False
                    }
                },
                "serverInfo": {
                    "name": "academic-rag-server-standalone",
                    "version": "1.0.0-standalone"
                }
            },
            "id": request_id
        }
    
    def _try_initialize_full_rag(self):
        """å°è¯•åˆå§‹åŒ–å®Œæ•´çš„RAGç®¡é“"""
        try:
            logger.info("ğŸ”„ å°è¯•åˆå§‹åŒ–å®Œæ•´RAGç®¡é“...")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰APIå¯†é’¥
            api_key = os.environ.get('OPENAI_API_KEY')
            if not api_key or not self.validate_api_key(api_key):
                logger.warning("âŒ APIå¯†é’¥æ— æ•ˆï¼Œä½¿ç”¨ç®€å•æ£€ç´¢æ¨¡å¼")
                self.full_rag_available = False
                return
            
            # å°è¯•åˆå§‹åŒ–å®Œæ•´RAGç³»ç»Ÿ
            if HAS_FULL_DEPS:
                try:
                    # åˆå§‹åŒ–æ–‡æ¡£å­˜å‚¨ (InMemoryDocumentStore with embedding support)
                    self.document_store = HaystackDocumentStore()
                    logger.info("âœ… æ–‡æ¡£å­˜å‚¨å·²åˆå§‹åŒ–")
                    
                    # åˆå§‹åŒ–åµŒå…¥å¤„ç†å™¨
                    self.embedding_processor = HaystackEmbeddingProcessor(
                        document_store=self.document_store,
                        model_name_or_path="sentence-transformers/all-MiniLM-L6-v2"
                    )
                    logger.info("âœ… åµŒå…¥å¤„ç†å™¨å·²åˆå§‹åŒ–")
                    
                    # åˆå§‹åŒ–LLMè¿æ¥å™¨
                    self.llm_connector = HaystackLLMConnector(
                        api_key=api_key,
                        model="gpt-3.5-turbo",
                        parameters={"temperature": 0.7}
                    )
                    logger.info("âœ… LLMè¿æ¥å™¨å·²åˆå§‹åŒ–")
                    
                    # åˆå§‹åŒ–RAGç®¡é“
                    self.rag_pipeline = RAGPipeline(
                        llm_connector=self.llm_connector,
                        document_store=self.document_store.get_haystack_store(),
                        retriever_top_k=5
                    )
                    logger.info("âœ… RAGç®¡é“å·²åˆå§‹åŒ–")
                    
                    self.full_rag_available = True
                    logger.info("ğŸ‰ å®Œæ•´RAGç®¡é“åˆå§‹åŒ–æˆåŠŸ (Sentence-BERT + OpenAI)")
                    return
                    
                except Exception as e:
                    logger.error(f"âŒ RAGç®¡é“åˆå§‹åŒ–å¤±è´¥: {e}", exc_info=True)
            
            self.full_rag_available = False
            logger.info("âš ï¸ ä½¿ç”¨ç®€å•æ£€ç´¢æ¨¡å¼")
            
        except Exception as e:
            logger.error(f"âŒ RAGåˆå§‹åŒ–é”™è¯¯: {e}", exc_info=True)
            self.full_rag_available = False
    
    async def handle_test_connection(self, request_id: Any, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†è¿æ¥æµ‹è¯• - é‡ç”¨SDKæ¨¡å¼"""
        message = arguments.get("message", "Hello MCP!")
        
        result_text = f"""âœ… MCP Academic RAG Server (Enhanced) è¿æ¥æˆåŠŸ!
ğŸ“© æ”¶åˆ°æ¶ˆæ¯: {message}
ğŸ• æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}
ğŸ Python: {sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}
ğŸ“ å·¥ä½œç›®å½•: {os.getcwd()}
ğŸ“š å·²å¤„ç†æ–‡æ¡£: {len(self.document_processor.documents)}
ğŸ”§ ä¾èµ–çŠ¶æ€: {'å®Œæ•´ä¾èµ–' if HAS_FULL_DEPS else 'ç®€åŒ–æ¨¡å¼'}
ğŸ› ï¸ æœåŠ¡å™¨ä¸Šä¸‹æ–‡: {'å·²åˆå§‹åŒ–' if self.server_context.is_initialized else 'æœªåˆå§‹åŒ–'}
ğŸ§  RAGç®¡é“: {'âœ… å¯ç”¨ (Sentence-BERT + OpenAI)' if hasattr(self, 'full_rag_available') and self.full_rag_available else 'âŒ ä¸å¯ç”¨ (å…³é”®è¯åŒ¹é…)'}
ğŸ¯ åµŒå…¥æ¨¡å‹: {'sentence-transformers/all-MiniLM-L6-v2' if hasattr(self, 'full_rag_available') and self.full_rag_available else 'æ— '}
ğŸ¤– ç”Ÿæˆæ¨¡å‹: {'OpenAI GPT-3.5-turbo' if hasattr(self, 'full_rag_available') and self.full_rag_available else 'æ— '}"""
        
        return {
            "jsonrpc": "2.0",
            "result": {
                "content": [{
                    "type": "text",
                    "text": result_text
                }]
            },
            "id": request_id
        }
    
    async def handle_validate_system(self, request_id: Any, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†ç³»ç»ŸéªŒè¯ - é‡ç”¨ç°æœ‰é€»è¾‘"""
        env_status = self.validate_environment()
        context_status = self.server_context.get_status()
        
        result_text = f"""ğŸ” ç³»ç»ŸéªŒè¯æŠ¥å‘Š:

ğŸ”‘ APIå¯†é’¥: {'æœ‰æ•ˆ' if env_status['api_key_valid'] else 'æ— æ•ˆ'} (é•¿åº¦: {env_status['api_key_length']})
ğŸ“ æ•°æ®ç›®å½•: {'å­˜åœ¨' if env_status['data_path_exists'] else 'ä¸å­˜åœ¨'}
ğŸ Pythonç‰ˆæœ¬: {env_status['python_version']}
ğŸ“‚ å·¥ä½œç›®å½•: {env_status['working_directory']}
ğŸ• æ£€æŸ¥æ—¶é—´: {env_status['timestamp']}

ğŸ—ï¸ æœåŠ¡å™¨çŠ¶æ€:
  â€¢ æœåŠ¡å™¨ä¸Šä¸‹æ–‡: {'å·²åˆå§‹åŒ–' if context_status['initialized'] else 'æœªåˆå§‹åŒ–'}
  â€¢ é…ç½®ç®¡ç†å™¨: {'å·²åŠ è½½' if context_status['config_loaded'] else 'æœªåŠ è½½'}
  â€¢ æ–‡æ¡£ç®¡é“: {'å°±ç»ª' if context_status['pipeline_ready'] else 'æœªå°±ç»ª'}
  â€¢ RAGç®¡é“: {'å¯ç”¨' if context_status['rag_enabled'] else 'ç¦ç”¨'}
  â€¢ å¤„ç†å™¨æ•°é‡: {context_status['processors_count']}

ğŸ“š æ–‡æ¡£å¤„ç†çŠ¶æ€:
  â€¢ å·²å¤„ç†æ–‡æ¡£: {len(self.document_processor.documents)}
  â€¢ ä¾èµ–æ¨¡å¼: {'å®Œæ•´ä¾èµ–' if HAS_FULL_DEPS else 'ç®€åŒ–æ¨¡å¼'}"""
        
        if 'data_path' in env_status:
            result_text += f"\nğŸ“‚ æ•°æ®è·¯å¾„: {env_status['data_path']}"
        if 'data_path_error' in env_status:
            result_text += f"\nâŒ æ•°æ®è·¯å¾„é”™è¯¯: {env_status['data_path_error']}"
        
        return {
            "jsonrpc": "2.0",
            "result": {
                "content": [{
                    "type": "text",
                    "text": result_text
                }]
            },
            "id": request_id
        }
    
    async def handle_process_document(self, request_id: Any, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†æ–‡æ¡£å¤„ç†è¯·æ±‚ - é‡ç”¨Documentæ¨¡å‹"""
        file_path = arguments.get("file_path", "")
        file_name = arguments.get("file_name", "")
        
        if not file_path:
            return {
                "jsonrpc": "2.0",
                "error": {
                    "code": -32602,
                    "message": "ç¼ºå°‘å¿…éœ€å‚æ•°: file_path"
                },
                "id": request_id
            }
        
        if not os.path.exists(file_path):
            return {
                "jsonrpc": "2.0",
                "result": {
                    "content": [{
                        "type": "text",
                        "text": f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"
                    }]
                },
                "id": request_id
            }
        
        # æ£€æŸ¥æ”¯æŒçš„æ–‡ä»¶ç±»å‹
        file_ext = Path(file_path).suffix.lower()
        text_types = ['.txt', '.md', '.rst', '.py', '.js', '.html', '.css', '.json', '.xml', '.csv']
        pdf_types = ['.pdf']
        supported_types = text_types + pdf_types
        
        if file_ext not in supported_types:
            return {
                "jsonrpc": "2.0",
                "result": {
                    "content": [{
                        "type": "text",
                        "text": f"âŒ æš‚ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_ext}\næ”¯æŒçš„ç±»å‹:\nâ€¢ æ–‡æœ¬æ–‡ä»¶: {', '.join(text_types)}\nâ€¢ PDFæ–‡ä»¶: {', '.join(pdf_types)}"
                    }]
                },
                "id": request_id
            }
        
        # å¤„ç†æ–‡æ¡£
        result = self.document_processor.process_document(file_path)
        
        if result["success"]:
            doc = result["document"]
            embedding_result = result.get("embedding_result")
            
            result_text = f"""âœ… æ–‡æ¡£å¤„ç†æˆåŠŸ!

ğŸ“„ æ–‡ä»¶ä¿¡æ¯:
  â€¢ è·¯å¾„: {file_path}
  â€¢ åç§°: {file_name if file_name else doc.file_name}
  â€¢ ç±»å‹: {file_ext}
  â€¢ çŠ¶æ€: {doc.status}

ğŸ†” æ–‡æ¡£ID: {doc.document_id}

ğŸ“Š å†…å®¹ç»Ÿè®¡:
  â€¢ å­—ç¬¦æ•°: {doc.metadata.get('char_count', 0):,}
  â€¢ å•è¯æ•°: {doc.metadata.get('word_count', 0):,}
  â€¢ è¡Œæ•°: {doc.metadata.get('line_count', 0):,}

ğŸ§  RAGå¤„ç†çŠ¶æ€: {doc.metadata.get('rag_processing', 'æœªçŸ¥')}"""

            # å¦‚æœæœ‰åµŒå…¥å¤„ç†ç»“æœï¼Œæ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
            if embedding_result:
                result_text += f"""
ğŸ“Š å‘é‡åµŒå…¥ä¿¡æ¯:
  â€¢ æ–‡æ¡£åˆ†å—æ•°: {embedding_result.get('chunks', 0)}
  â€¢ åµŒå…¥æ¨¡å‹: sentence-transformers/all-MiniLM-L6-v2
  â€¢ å‘é‡ç»´åº¦: 384ç»´"""

            result_text += f"""

âœ… æ–‡æ¡£å·²æˆåŠŸå¤„ç†å¹¶å»ºç«‹ç´¢å¼•ï¼Œå¯ä»¥ä½¿ç”¨ query_documents å·¥å…·è¿›è¡Œ{'æ™ºèƒ½RAGæŸ¥è¯¢' if doc.metadata.get('rag_processing') == 'completed' else 'å…³é”®è¯æŸ¥è¯¢'}ã€‚"""
        else:
            result_text = f"""âŒ æ–‡æ¡£å¤„ç†å¤±è´¥:

ğŸ“„ æ–‡ä»¶è·¯å¾„: {file_path}
ğŸ’¬ é”™è¯¯ä¿¡æ¯: {result['error']}

è¯·æ£€æŸ¥:
â€¢ æ–‡ä»¶æ˜¯å¦å¯è¯»
â€¢ æ–‡ä»¶ç¼–ç æ˜¯å¦æ­£ç¡® (å»ºè®®UTF-8)
â€¢ æ–‡ä»¶æƒé™æ˜¯å¦å……è¶³"""
        
        return {
            "jsonrpc": "2.0",
            "result": {
                "content": [{
                    "type": "text",
                    "text": result_text
                }]
            },
            "id": request_id
        }
    
    async def handle_query_documents(self, request_id: Any, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†æ–‡æ¡£æŸ¥è¯¢è¯·æ±‚ - å®Œæ•´RAGå®ç°"""
        query = arguments.get("query", "")
        top_k = arguments.get("top_k", 5)
        session_id = arguments.get("session_id", "")
        
        if not query:
            return {
                "jsonrpc": "2.0",
                "error": {
                    "code": -32602,
                    "message": "ç¼ºå°‘å¿…éœ€å‚æ•°: query"
                },
                "id": request_id
            }
        
        if len(self.document_processor.documents) == 0:
            return {
                "jsonrpc": "2.0",
                "result": {
                    "content": [{
                        "type": "text",
                        "text": "âŒ æ²¡æœ‰å·²å¤„ç†çš„æ–‡æ¡£ã€‚\n\nè¯·å…ˆä½¿ç”¨ process_document å·¥å…·å¤„ç†ä¸€äº›æ–‡æ¡£ã€‚"
                    }]
                },
                "id": request_id
            }
        
        try:
            # å¦‚æœå®Œæ•´RAGå¯ç”¨ï¼Œä½¿ç”¨RAGç®¡é“
            if hasattr(self, 'full_rag_available') and self.full_rag_available and hasattr(self, 'rag_pipeline'):
                logger.info(f"ğŸ¤– ä½¿ç”¨å®Œæ•´RAGç®¡é“æŸ¥è¯¢: {query}")
                
                try:
                    # è¿è¡ŒRAGç®¡é“
                    rag_result = self.rag_pipeline.run(
                        query=query,
                        chat_history=[],  # ç®€åŒ–å®ç°ï¼Œä¸ä½¿ç”¨å†å²è®°å½•
                        filters=None,  # ä¸ä½¿ç”¨è¿‡æ»¤å™¨
                        generation_kwargs={"temperature": 0.7}
                    )
                    
                    if 'error' not in rag_result:
                        # RAGæˆåŠŸï¼Œè¿”å›å®Œæ•´çš„æ™ºèƒ½ç­”æ¡ˆ
                        answer = rag_result.get("answer", "æ— æ³•ç”Ÿæˆç­”æ¡ˆ")
                        documents = rag_result.get("documents", [])
                        
                        result_text = f"""ğŸ¤– æ™ºèƒ½RAGæŸ¥è¯¢ç»“æœ:

â“ é—®é¢˜: {query}

ğŸ’¬ AIç­”æ¡ˆ:
{answer}

ğŸ“ ç›¸å…³æ–‡æ¡£ç‰‡æ®µ (å‰{len(documents[:top_k])}ä¸ª):
"""
                        
                        for i, doc in enumerate(documents[:top_k], 1):
                            content = doc.get("content", "")
                            if len(content) > 200:
                                content = content[:200] + "..."
                            
                            metadata = doc.get("metadata", {})
                            file_name = metadata.get("file_name", "æœªçŸ¥")
                            
                            result_text += f"\n{i}. ğŸ“„ {file_name}\n   ğŸ“ {content}\n"
                        
                        result_text += f"\nğŸ” æ£€ç´¢æ¨¡å¼: åµŒå…¥å‘é‡åŒ¹é… (Sentence-BERT)"
                        result_text += f"\nğŸ¤– ç”Ÿæˆæ¨¡å¼: OpenAI GPT (LLM)"
                        
                        if session_id:
                            result_text += f"\nğŸ†” ä¼šè¯ID: {session_id}"
                        
                        return {
                            "jsonrpc": "2.0",
                            "result": {
                                "content": [{
                                    "type": "text",
                                    "text": result_text
                                }]
                            },
                            "id": request_id
                        }
                    else:
                        logger.warning(f"âš ï¸ RAGç®¡é“è¿”å›é”™è¯¯: {rag_result.get('error')}")
                        
                except Exception as e:
                    logger.error(f"âŒ RAGç®¡é“æ‰§è¡Œå¼‚å¸¸: {e}", exc_info=True)
                    # å›é€€åˆ°ç®€å•æ¨¡å¼
            
            # å›é€€åˆ°ç®€å•å…³é”®è¯åŒ¹é…æ¨¡å¼
            logger.info(f"ğŸ” ä½¿ç”¨ç®€å•å…³é”®è¯åŒ¹é…æ¨¡å¼æŸ¥è¯¢: {query}")
            results = self.document_processor.search_documents(query, top_k)
            
            if not results:
                result_text = f"""ğŸ” æŸ¥è¯¢ç»“æœ:

â“ æŸ¥è¯¢: {query}
ğŸ“Š ç»“æœ: æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£

ğŸ’¡ å»ºè®®:
â€¢ å°è¯•æ›´é€šç”¨çš„å…³é”®è¯
â€¢ æ£€æŸ¥æ‹¼å†™æ˜¯å¦æ­£ç¡®
â€¢ ç¡®è®¤ç›¸å…³å†…å®¹å·²è¢«å¤„ç†

ğŸ” æ£€ç´¢æ¨¡å¼: å…³é”®è¯åŒ¹é… (ç®€å•æ¨¡å¼)"""
            else:
                result_text = f"""ğŸ” å…³é”®è¯åŒ¹é…æŸ¥è¯¢ç»“æœ:

â“ æŸ¥è¯¢: {query}
ğŸ“Š æ‰¾åˆ° {len(results)} ä¸ªç›¸å…³æ–‡æ¡£:

"""
                for i, result in enumerate(results, 1):
                    doc = result["document"]
                    result_text += f"""ğŸ“„ ç»“æœ {i}:
  â€¢ æ–‡ä»¶: {doc.file_name}
  â€¢ æ–‡æ¡£ID: {doc.document_id[:8]}...
  â€¢ ç›¸å…³æ€§: {result['score']} åˆ†
  â€¢ å­—æ•°: {doc.metadata.get('word_count', 0):,}
  â€¢ é¢„è§ˆ: {result['snippet'][:150]}...

"""
                result_text += f"\nğŸ” æ£€ç´¢æ¨¡å¼: å…³é”®è¯åŒ¹é… (ç®€å•æ¨¡å¼)"
                
            if session_id:
                result_text += f"\nğŸ†” ä¼šè¯ID: {session_id}"
            
            return {
                "jsonrpc": "2.0",
                "result": {
                    "content": [{
                        "type": "text",
                        "text": result_text
                    }]
                },
                "id": request_id
            }
            
        except Exception as e:
            logger.error(f"âŒ æŸ¥è¯¢æ‰§è¡Œå¼‚å¸¸: {e}", exc_info=True)
            return {
                "jsonrpc": "2.0",
                "error": {
                    "code": -32603,
                    "message": f"æŸ¥è¯¢æ‰§è¡Œå¤±è´¥: {str(e)}"
                },
                "id": request_id
            }
    
    async def handle_list_documents(self, request_id: Any, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†æ–‡æ¡£åˆ—è¡¨è¯·æ±‚"""
        docs = self.document_processor.documents
        
        if not docs:
            result_text = """ğŸ“š æ–‡æ¡£åˆ—è¡¨:

æš‚æ— å·²å¤„ç†çš„æ–‡æ¡£ã€‚

ä½¿ç”¨ process_document å·¥å…·æ¥å¤„ç†æ–‡æ¡£:
â€¢ æ”¯æŒçš„æ ¼å¼: .txt, .md, .rst, .py, .js, .html, .css, .json, .xml, .csv
â€¢ å¤„ç†åå¯ä½¿ç”¨ query_documents è¿›è¡ŒæŸ¥è¯¢"""
        else:
            result_text = f"ğŸ“š æ–‡æ¡£åˆ—è¡¨ (å…± {len(docs)} ä¸ª):\n\n"
            
            for i, (doc_id, doc) in enumerate(docs.items(), 1):
                result_text += f"""{i}. ğŸ“„ {doc.file_name}
   ğŸ†” ID: {doc_id[:8]}...
   ğŸ“Š {doc.metadata.get('word_count', 0):,} è¯, {doc.metadata.get('char_count', 0):,} å­—ç¬¦
   ğŸ“ è·¯å¾„: {doc.file_path}
   â° åˆ›å»º: {doc.creation_time}
   ğŸ”„ çŠ¶æ€: {doc.status}

"""
        
        return {
            "jsonrpc": "2.0",
            "result": {
                "content": [{
                    "type": "text",
                    "text": result_text
                }]
            },
            "id": request_id
        }
    
    async def run(self):
        """è¿è¡ŒMCPæœåŠ¡å™¨"""
        logger.info("Starting MCP Academic RAG Server (Standalone)")
        
        try:
            while True:
                line = await asyncio.get_event_loop().run_in_executor(
                    None, sys.stdin.readline
                )
                
                if not line.strip():
                    continue
                
                try:
                    request = json.loads(line)
                    method = request.get("method")
                    request_id = request.get("id")
                    params = request.get("params", {})
                    
                    logger.debug(f"Received request: {method}")
                    
                    if method == "initialize":
                        response = await self.handle_initialize(request_id, params)
                    elif method == "tools/list":
                        response = await self.handle_list_tools(request_id)
                    elif method == "tools/call":
                        response = await self.handle_call_tool(request_id, params)
                    else:
                        response = {
                            "jsonrpc": "2.0",
                            "error": {
                                "code": -32601,
                                "message": f"Method not found: {method}"
                            },
                            "id": request_id
                        }
                    
                    print(json.dumps(response))
                    sys.stdout.flush()
                    
                except json.JSONDecodeError as e:
                    logger.error(f"JSON decode error: {e}")
                    continue
                except Exception as e:
                    logger.error(f"Request handling error: {e}", exc_info=True)
                    error_response = {
                        "jsonrpc": "2.0",
                        "error": {
                            "code": -32603,
                            "message": f"Internal error: {str(e)}"
                        },
                        "id": request.get("id") if 'request' in locals() else None
                    }
                    print(json.dumps(error_response))
                    sys.stdout.flush()
                    
        except KeyboardInterrupt:
            logger.info("Server shutdown requested")
        except Exception as e:
            logger.error(f"Server error: {str(e)}", exc_info=True)

def main():
    """ä¸»å…¥å£ç‚¹"""
    if len(sys.argv) > 1 and sys.argv[1] == "--validate-only":
        # éªŒè¯æ¨¡å¼
        server = MCPServer()
        env_status = server.validate_environment()
        
        if env_status["api_key_valid"]:
            print("âœ… ç‹¬ç«‹æœåŠ¡å™¨ç¯å¢ƒéªŒè¯é€šè¿‡", file=sys.stderr)
            sys.exit(0)
        else:
            print("âŒ APIå¯†é’¥éªŒè¯å¤±è´¥", file=sys.stderr)
            sys.exit(1)
    else:
        # MCPæœåŠ¡å™¨æ¨¡å¼
        server = MCPServer()
        asyncio.run(server.run())

if __name__ == "__main__":
    main()